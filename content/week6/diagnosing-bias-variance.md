---
title: "تشخیص بایاس در مقابل واریانس"
date: 2020-10-16T19:43:49.155Z
draft: false
weight: 30
---

در این بخش به بررسی رابطه بین درجه چند جمله ای (d) و underfit و یا overfit بودن فرضیه می‌پردازیم.

- در ابتدا لازم است که تشخیص دهیم، عاملی که باعث پیش بینی نادرست شده بایاس است یا واریانس؟
- بایاس زیاد همان underfitting و واریانس زیاد همان overfitting است که باید یک میانگین مناسب بین این دو مقدار انتخاب شود.

مادامی که ما درجه چندجمله ای را افزایش می‌دهیم، خطای آموزش کاهش می‌یابد.

خطای cross validation  نیز با افزایش مقدار d تا یک نقطه مشخص، کاهش یافته و در ادامه با افزایش مقدار d، افزایش می‌یابد که این مسئله موجب به وجود آمدن یک منحنی محدب می شود. (منحنی سیز رنگ در شکل زیر)

 **بایاس زیاد (underfitting):** $J_{train}(\Theta )$ و $J_{CV}(\Theta )$ هردو مقادیر بزرگی خواهند بود. همچنین $J_{CV}(\Theta ) \approx J_{train}(\Theta )$.

**واریانس زیاد(overfitting):** $J_{train}(\Theta )$ مقداری کوچک و $J_{CV}(\Theta )$ مقداری بسیار بزرگ تر از $J_{train}(\Theta )$ خواهد داشت که در تصویر زیر نمایش داده شده است:

![underfitting-overfitting](../images/underfit-overfit.jpg)