---
title: "منحنی های یادگیری"
date: 2020-10-16T19:43:49.155Z
draft: false
weight: 50
---

آموزش 3 نمونه به آسانی خطایی برابر با صفر خواهد داشت زیرا امکان پیدا کردن یک منحنی درجه دو که دقیقا با سه نقطه برخورد کند همیشه وجود دارد.

- همچنان که مجموعه آموزشی بزرگتر می شود، خطای تابع درجه دو افزایش می یابد.

- مقدار خطا پس از اندازه معین m یا مجموعه اموزشی کم و ثابت خواهد بود.

**مقدار بایاس بالا**

**مجموعه آموزشی کوچک:** باعث می شود تا  $J_{train}\left ( \Theta  \right )$ کم و $J_{cv}\left ( \Theta  \right )$ زیاد باشد.

**مجموعه آموزشی بزرگ:** باعث می شود تا $J_{train}\left ( \Theta  \right )$ و $J_{CV}\left ( \Theta  \right )$ هردو مقدار بالایی داشته باشند و $J_{train}\left ( \Theta  \right ) \approx J_{CV}\left ( \Theta  \right )$

اگر یک الگوریتم با مشکل **بایاس بالا** مواجه باشد، اضافه کردن داده آموزشی **(به تنهایی) موثر نخواهد بود.**

برای مقدار واریانس بالا، روابط زیر را به لحاظ اندازه مجموعه آموزشی داریم:

**مقدار واریانس بالا**
**مجموعه آموزشی کوچک:** $J_{train}\left ( \Theta  \right )$ مقدار کم و $J_{CV}\left ( \Theta  \right )$ مقدار بالایی داشته باشد.

**مجموعه آموزشی بزرگ:** $J_{train}\left ( \Theta  \right )$ متناسب با اندازه مجموعه آموزشی افزایش می یابد و $J_{CV}\left ( \Theta  \right )$ بدون ثابت شدن کاهش می یابد. همچنین $J_{train}\left ( \Theta  \right ) <  J_{CV}\left ( \Theta  \right )$ خواهد بود و اختلاف قابل توجهی خواهند داشت.

اگر یک الگوریتم با مشکل **واریانس بالا** مواجه باشد، داده آموزشی بیشتر **احتمالا موثر خواهد بود.**

![High Bias](../images/high-bias.jpg)

![High Variance](../images/high-variance.jpg)

