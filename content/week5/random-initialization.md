---
title: "مقدار دهی اولیه تصادفی"
date: 2020-10-11T17:13:59+03:30
draft: false
weight: 60
---

مقدار دهی اولیه همه وزن های تتا (theta weights) به مقدار
$0$ برای شبکه های عصبی کار ساز نیست!

وقتی از Backpropagation استفاده می‌کنیم،
همه گره ها به طور مکرر به یک مقدار مشابه به روز می‌شوند.
اما در عوض می‌توانیم وزن های ماتریس $\Theta$ خودمان را به روش زیر به صورت تصادفی مقدار دهی کنیم:

![image3.png](../images/image3.png?width=35pc)

از این رو، ما هر $\Theta _{ij} ^{(l)}$ را به صورت
عددی تصادفی بین $[ - \epsilon, \epsilon]$ مقدار دهی می‌کنیم،
و استفاده از فرمول بالا تضمین می‌کند که این حد مد نظر را به دست می‌آوریم، همین رویه برای
همه $\Theta$ ها انجام می‌شود.

در زیر قطعه کدی است که می‌توانید این موضوع را آزمایش کنید:

<div align="left">

```
If the dimensions of Theta1 is 10x11, Theta2 is 10x11 and Theta3 is 1x11

;Theta1 = rand(10,11) * (2 * INIT_EPSILON) - INIT_EPSILON
;Theta2 = rand(10,11) * (2 * INIT_EPSILON) - INIT_EPSILON
;Theta3 = rand(1,11) * (2 * INIT_EPSILON) - INIT_EPSILON
```

</div>

**rand(x,y)** تابعی در octave است که 
ماتریسی از اعداد حقیقی تصادفی بین 0 و 1 ایجاد می‌کند.


{{% notice note %}}
اپسیلون استفاده شده در بالا ربطی به اپسیلون استفاده شده در قسمت بررسی گرادیان ندارد.
{{% /notice %}}


